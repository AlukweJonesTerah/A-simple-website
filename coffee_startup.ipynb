{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlukweJonesTerah/A-simple-website/blob/main/coffee_startup.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNqpB8OsiZ0Q"
      },
      "outputs": [],
      "source": [
        "#!pip install kaggle\n",
        "#!pip install tensorflow\n",
        "#!pip install pillow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mL8GICfSjtt3"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import PIL\n",
        "import shutil\n",
        "import random\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os, warnings\n",
        "from PIL import Image\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense, RandomFlip, RandomRotation, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from google.colab import drive, files\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import confusion_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mount drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQDew5f1oY0c",
        "outputId": "4df1f6f1-ef07-4a95-c576-2827f7835a14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "coffee_dataset_path = '/content/drive/MyDrive/coffee_dataset'\n",
        "folder_contents = os.listdir (coffee_dataset_path)\n",
        "print(\"contents of coffee dataset: \", folder_contents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9mhPhEFUootG",
        "outputId": "c9c9553d-f404-4852-e33e-4997ae81a706"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "contents of coffee dataset:  ['healthy_coffee', 'Cerscospora_leaf_spot', 'Phoma_leaf_spot']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = '/content/drive/MyDrive/coffee_dataset/'\n",
        "#data_dir = pathlib.Path(data_dir).with_suffix('')"
      ],
      "metadata": {
        "id": "pCvQWTPUqGbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bad_img_list=[]\n",
        "total=0\n",
        "good=0\n",
        "bad=0\n",
        "\n",
        "classes=sorted(os.listdir(data_dir))\n",
        "\n",
        "print(classes)\n",
        "for klass in classes:\n",
        "    good_class=0\n",
        "    bad_class=0\n",
        "    total_class=0\n",
        "    msg=f'processing class {klass}'\n",
        "    print(msg, '\\r', end= '')\n",
        "    classpath=os.path.join(data_dir, klass)\n",
        "    flist=sorted(os.listdir(classpath))\n",
        "    for f in flist:\n",
        "        total +=1\n",
        "        total_class +=1\n",
        "        fpath=os.path.join(classpath,f)\n",
        "        try:\n",
        "            img= Image.open(fpath)\n",
        "            array=np.asarray(img)\n",
        "            good +=1\n",
        "            good_class +=1\n",
        "        except:\n",
        "            bad_img_list.append(fpath)\n",
        "            bad +=1\n",
        "            bad_class +=1\n",
        "\n",
        "    msg=f'class {klass} contains {total_class} files, {good_class} are valid image files and {bad_class} defective image files'\n",
        "    print (msg)\n",
        "msg=f'the dataset contains {total} image files, {good} are valid image files and {bad} are defective image files'\n",
        "print (msg)\n",
        "if bad>0:\n",
        "    ans=input('to print a list of defective image files enter P, to not print press Enter')\n",
        "    if ans == 'P' or ans == 'p':\n",
        "        for f in bad_img_list:\n",
        "            print (f)\n",
        "\n"
      ],
      "metadata": {
        "id": "vQg4t1cn0W-P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f922d44-b77d-4168-9fbe-957629c598d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Cerscospora_leaf_spot', 'Phoma_leaf_spot', 'healthy_coffee']\n",
            "class Cerscospora_leaf_spot contains 7701 files, 7701 are valid image files and 0 defective image files\n",
            "class Phoma_leaf_spot contains 6591 files, 6591 are valid image files and 0 defective image files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_data_dir = data_dir\n",
        "test_data_dir = data_dir\n",
        "\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255.,rotation_range = 40, width_shift_range = 0.2, height_shift_range = 0.2, shear_range = 0.2, zoom_range = 0.2, horizontal_flip = True)\n",
        "\n",
        "\n",
        "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OqKdO3Jv1WLd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(data_dir, batch_size = 20, class_mode = 'categorical', target_size = (224, 224))\n",
        "\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "validation_generator = test_datagen.flow_from_directory( data_dir,  batch_size = 20, class_mode = 'categorical', target_size = (224, 224))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAScqG10N2RJ",
        "outputId": "f596266e-d64c-43bd-e88d-2d03b6568137"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 18618 images belonging to 3 classes.\n",
            "Found 18618 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "base_model = VGG16(input_shape = (224, 224, 3), # Shape of our images\n",
        "include_top = False, # Leave out the last fully connected layer\n",
        "weights = 'imagenet')"
      ],
      "metadata": {
        "id": "sxZfia3mOb7h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "5pVyUs9dOhoc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(base_model.output)\n",
        "\n",
        "# Add a fully connected layer with 512 hidden units and ReLU activation\n",
        "x = layers.Dense(512, activation='relu')(x)\n",
        "\n",
        "# Add a dropout rate of 0.5\n",
        "x = layers.Dropout(0.5)(x)\n",
        "\n",
        "# Add a final softmax layer with 1 node for classification output\n",
        "x = layers.Dense(3, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.models.Model(base_model.input, x)\n",
        "\n",
        "model.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0001), loss = 'categorical_crossentropy',metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "YimBoWhxOmoG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=\"best_model.h5\",\n",
        "    save_best_only=True,\n",
        "    monitor=\"val_loss\",\n",
        "    mode=\"min\",\n",
        "    verbose=1\n",
        ")\n",
        "early_stopping_callback = EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=3,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "reduce_lr_callback=ReduceROnPlateau(\n",
        "    monitor=\"val_loss\",\n",
        "    factor=0.2,\n",
        "    patience=2,\n",
        "    min_lr=0.0001\n",
        ")"
      ],
      "metadata": {
        "id": "0RAvVOOqehTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgghist = model.fit(\n",
        "    train_generator,\n",
        "    validation_data = validation_generator,\n",
        "    steps_per_epoch = 100,\n",
        "    epochs = 10,\n",
        "    callback=[\n",
        "        model_checkpoint_callback,\n",
        "        early_stopping_callback,\n",
        "        reduce_lr_callback\n",
        "    ]\n",
        "    )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7S1WT39OshO",
        "outputId": "bf49cb86-3fe2-442e-9f65-ad5a24134c0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "100/100 [==============================] - 197s 2s/step - loss: 0.5722 - accuracy: 0.7705 - val_loss: 0.1614 - val_accuracy: 0.9669\n",
            "Epoch 2/10\n",
            "100/100 [==============================] - 125s 1s/step - loss: 0.2467 - accuracy: 0.9025 - val_loss: 0.2966 - val_accuracy: 0.8606\n",
            "Epoch 3/10\n",
            "100/100 [==============================] - 126s 1s/step - loss: 0.1893 - accuracy: 0.9274 - val_loss: 0.0476 - val_accuracy: 0.9901\n",
            "Epoch 4/10\n",
            "100/100 [==============================] - 174s 2s/step - loss: 0.1347 - accuracy: 0.9540 - val_loss: 0.0739 - val_accuracy: 0.9875\n",
            "Epoch 5/10\n",
            "100/100 [==============================] - 174s 2s/step - loss: 0.1211 - accuracy: 0.9510 - val_loss: 0.0356 - val_accuracy: 0.9931\n",
            "Epoch 6/10\n",
            "100/100 [==============================] - 124s 1s/step - loss: 0.1282 - accuracy: 0.9555 - val_loss: 0.0344 - val_accuracy: 0.9875\n",
            "Epoch 7/10\n",
            "100/100 [==============================] - 127s 1s/step - loss: 0.1034 - accuracy: 0.9615 - val_loss: 0.0454 - val_accuracy: 0.9793\n",
            "Epoch 8/10\n",
            "100/100 [==============================] - 126s 1s/step - loss: 0.1047 - accuracy: 0.9610 - val_loss: 0.0210 - val_accuracy: 0.9953\n",
            "Epoch 9/10\n",
            "100/100 [==============================] - 128s 1s/step - loss: 0.0863 - accuracy: 0.9635 - val_loss: 0.0141 - val_accuracy: 0.9979\n",
            "Epoch 10/10\n",
            "100/100 [==============================] - 174s 2s/step - loss: 0.1024 - accuracy: 0.9655 - val_loss: 0.0113 - val_accuracy: 0.9979\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "model.save('model_1.h5')"
      ],
      "metadata": {
        "id": "oQBXeELdgYqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pU5JwbZ6Owf0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}